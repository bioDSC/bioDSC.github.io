[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "The bioDSC blog",
    "section": "",
    "text": "Should I learn Python or R?\n\n\n\n\n\n\ngeneral\n\n\nworkshop-related\n\n\n\n\n\n\n\n\n\nDec 13, 2024\n\n\nMartijn Wehrens\n\n\n\n\n\n\n\nVisualizing Arabidopsis whole-genome alignments\n\n\n\n\n\n\ncomparative genomics\n\n\narabidopsis\n\n\ncrunchomics\n\n\n\nLearn how to plot genome rearrangements in this blog.\n\n\n\n\n\nNov 4, 2024\n\n\nMisha Paauw\n\n\n\n\n\n\n\nThe bioDSC blog: first post\n\n\n\n\n\n\nintro\n\n\ngeneral\n\n\n\nAn introduction to the blog and its purpose.\n\n\n\n\n\nOct 30, 2024\n\n\nMisha Paauw\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "*bio*DSC",
    "section": "",
    "text": "Tutorial pages will be uploaded to this section of the site! Stay tuned!"
  },
  {
    "objectID": "tutorials.html#tutorials",
    "href": "tutorials.html#tutorials",
    "title": "*bio*DSC",
    "section": "",
    "text": "Tutorial pages will be uploaded to this section of the site! Stay tuned!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The biological Data Science Center",
    "section": "",
    "text": "As a biologist at the Science Park of the University of Amsterdam, it’s likely that you will generate large amounts of data. The biological Data Science Center (bioDSC) was initiated to help you analyse that data.\nOur aim is to enable you to perform analyses yourself, which is why we offer workshops, on-line tutorials and in-person mentoring. We have an open-door policy: we encourage you to send an email or drop by one of our desks when you need help or input with your data analysis problem. For quick questions, check out our Slack channel!\nSend an email Drop by Slack"
  },
  {
    "objectID": "index.html#our-approach",
    "href": "index.html#our-approach",
    "title": "The biological Data Science Center",
    "section": "Our approach",
    "text": "Our approach\n\n\nThe bioDSC was initiated in September ’24, and we are currently finding out what works best to optimally support people with their data analyses.\nOur core members are embedded in several research groups at the Swammerdam Institute for Life Sciences (SILS), to be integrated in the community of researchers at Science Park. In addition, other researchers at SILS sometimes volunteer to further support data analyses and good practices."
  },
  {
    "objectID": "index.html#check-out-our-online-resources",
    "href": "index.html#check-out-our-online-resources",
    "title": "The biological Data Science Center",
    "section": "Check out our online resources",
    "text": "Check out our online resources\nCheck out our blog for quick reads on coding, which maybe inspiring for your research. Check out our tutorials for full protocols on analyses that are often performed by biologists at the UvA Science Park, such as RNA-seq.\nBlog Tutorials Further reading"
  },
  {
    "objectID": "index.html#check-out-our-workshops",
    "href": "index.html#check-out-our-workshops",
    "title": "The biological Data Science Center",
    "section": "Check out our workshops",
    "text": "Check out our workshops\nOur aim is to organize workshops on topics researchers are interested in and that will help them. We’re currently working on composing a list of workshops and will start to organize them soon. Check out our workshop page to see whether we already have a workshop that is of interest to you. If you’re interested in a topic that’s not on the list, don’t hesitate to send us an email or drop by. We can either help you out with your specific problem, or organize a workshop if it’s a topic of potential interest to many researchers.\nWorkshops"
  },
  {
    "objectID": "index.html#history",
    "href": "index.html#history",
    "title": "The biological Data Science Center",
    "section": "History",
    "text": "History\n\n\nAt the University of Amsterdam Science Park, enthusiastic researchers started the Science Park Study Group in 2017. The idea was to create a local culture of connecting and sharing knowledge with regard to coding in the biological sciences. Having started in September ’24 with the bioDSC, we aim to further boast this initiative and spirit.\nThe original website of the Science Park Study group can be found here."
  },
  {
    "objectID": "posts/python-or-R.html",
    "href": "posts/python-or-R.html",
    "title": "Should I learn Python or R?",
    "section": "",
    "text": "When you haven’t had any exposure to scripting languages, but know some type of scripting language might be convenient to analyze your data, it might be hard to determine which language (R, Python, Javascript, ..) you should look into.\nIn this blog post I list some typical use cases of Python and R such that you have an impression which language you use for what."
  },
  {
    "objectID": "posts/python-or-R.html#motivation-for-writing-this-blog-post",
    "href": "posts/python-or-R.html#motivation-for-writing-this-blog-post",
    "title": "Should I learn Python or R?",
    "section": "",
    "text": "When you haven’t had any exposure to scripting languages, but know some type of scripting language might be convenient to analyze your data, it might be hard to determine which language (R, Python, Javascript, ..) you should look into.\nIn this blog post I list some typical use cases of Python and R such that you have an impression which language you use for what."
  },
  {
    "objectID": "posts/python-or-R.html#python-versus-r",
    "href": "posts/python-or-R.html#python-versus-r",
    "title": "Should I learn Python or R?",
    "section": "Python versus R",
    "text": "Python versus R\nWhen analyzing scientific data, there are multiple tools available. For simple analyses, Excel, GraphPad or FIJI/ImageJ may suffice. When handling large amounts of data, or when you demand more specialized, custom types of analyses, it becomes convenient to use scripting languages such as Python or R. Many programming and scripting languages exist, but the main ones many researchers use are R and Python, on which I’ll focus here.\nBelow a list of what people typically use R and Python for.\n\nR\nTypical use cases for R include:\n\nbioinformatics, including specialized packages for\n\ngenomics, transcriptomics, proteomics, e.g.\n\nGene annotation (GO terms)\nEnrichment analyses, differential gene expression\nSeurat package for single cell analysis\n\n\nextensive data visualization\n\n(through the ggplot library)\ndisplaying high-dimensional data e.g. in tSNE or UMAPs, PCA analysis etc\n\ncomplex statistical modeling, specialized e.g. for\n\nEcology\nBioinformatics (as mentioned above)\n\n\n\n\nPython\n\nImage analysis\n\nAlthough MATLAB is a go-to tool for image analysis, Python has become the open-source almost on-par alternative\nMultiple libraries are now available that can do pretty much any “classical” image operations to analyze images, e.g. to\n\nSegment your image (identify cells, or other parts of your image that are of interest)\nE.g. SciPy, OpenCV, scikit, ..\n\nMultiple tools exist to allow smooth user-interaction, such as Napari\n\nPlotting and analyzing large data sets\n\nWith the pandas, matplotlib, and seaborn library, large datasets can be imported, manipulated, and visualized\nThis offers similar capabilities as R\n\nMachine learning, neural networks, LLM, AI\n\nPython has become the go-to tool for working with machine learning related tech\n\nE.g. Keras and PyTorch\n\n\nhigh-throughput data analysis and automation\n\npython is often used to process large amounts of data for further processing (see bio-informatics below)\n\nbioinformatics\n\nseems there’s less tools available, however offers packages to:\nPerform single cell analysis, such as SCANPY\nCustom tasks in bioinformatics pipelines (specialized mapping, e.g.) can use python\n\n\nWhat ChatGPT had to say about it: “R excels at statistical and visualization tasks, particularly for biostatistics and bioinformatics, while Python is preferred for machine learning, automation, and handling diverse data types in scalable pipelines. Many researchers use both, leveraging each for its strengths.”"
  },
  {
    "objectID": "posts/python-or-R.html#so-what-should-i-choose",
    "href": "posts/python-or-R.html#so-what-should-i-choose",
    "title": "Should I learn Python or R?",
    "section": "So, what should I choose?",
    "text": "So, what should I choose?\nIf you’re uncertain what you should learn, feel free to drop us an email, walk by our desks, or contact us in another way to have a chat about what is most suitable for you!\nSend an email Drop by Slack"
  },
  {
    "objectID": "posts/Ath_synteny.html",
    "href": "posts/Ath_synteny.html",
    "title": "Visualizing Arabidopsis whole-genome alignments",
    "section": "",
    "text": "Interesting phenotypes can be encoded in the genome of organisms. Therefore, it is often interesting to visualize differences between genomes of different species, or of individuals within the same species. These differences could be small, such as single nucleotide polymorphisms, but can also be structural rearrangements of entire chromosomes.\nIn a recent publication, Lian et al 2024 Nature Genetics investigated structural rearrangements in a panel of 69 Arabidopsis thaliana accessions (Fig 3). In addition, they published a chromosome level assembly of Arabidopsis accession Oy-0. This accession is used in several research groups of the University of Amsterdam, so it is interesting to show genome rearrangements between this accession, and the model accession Col-0. The paper uses plotsr software to plot synteny across chromosomes. The syntenic regions are first identified using syri.\nSoftware used:\n\nsyri, a software package to identify structural rearrangements.\nplotsr, a software package to plot the rearrangements detected by syri.\nminimap2, a fast aligner, used here to align the two genomes of interest."
  },
  {
    "objectID": "posts/Ath_synteny.html#introduction",
    "href": "posts/Ath_synteny.html#introduction",
    "title": "Visualizing Arabidopsis whole-genome alignments",
    "section": "",
    "text": "Interesting phenotypes can be encoded in the genome of organisms. Therefore, it is often interesting to visualize differences between genomes of different species, or of individuals within the same species. These differences could be small, such as single nucleotide polymorphisms, but can also be structural rearrangements of entire chromosomes.\nIn a recent publication, Lian et al 2024 Nature Genetics investigated structural rearrangements in a panel of 69 Arabidopsis thaliana accessions (Fig 3). In addition, they published a chromosome level assembly of Arabidopsis accession Oy-0. This accession is used in several research groups of the University of Amsterdam, so it is interesting to show genome rearrangements between this accession, and the model accession Col-0. The paper uses plotsr software to plot synteny across chromosomes. The syntenic regions are first identified using syri.\nSoftware used:\n\nsyri, a software package to identify structural rearrangements.\nplotsr, a software package to plot the rearrangements detected by syri.\nminimap2, a fast aligner, used here to align the two genomes of interest."
  },
  {
    "objectID": "posts/Ath_synteny.html#the-data",
    "href": "posts/Ath_synteny.html#the-data",
    "title": "Visualizing Arabidopsis whole-genome alignments",
    "section": "The data",
    "text": "The data\nI downloaded the Arabidopsis Col-0 TAIR10.1 and Oy-0 genome assemblies with the following script, moved them to a folder called data, and unzipped them:\n(syri) [mpaauw@omics-h0 02_Ath_synteny]$ cat download_genoomes.sh \nwget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/036/927/085/GCA_036927085.1_ASM3692708v1/GCA_036927085.1_ASM3692708v1_genomic.fna.gz\nwget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/735/GCF_000001735.4_TAIR10.1/GCF_000001735.4_TAIR10.1_genomic.fna.gz\n\nmv GC* data/\ncd data/\ngunzip *.gz\nThe synteny software expects that homologous chromosomes in the two genomes have exactly the same chromosome id. Unfortunately, this is almost never the case if you download genomes from different organisms and from different sources. To rename the fasta headers, I used the following sed commands. In addition, I removed the mitochondrial and chromosomal DNA sequences.\n(syri) [mpaauw@omics-h0 data]$ cat chromosome_renamer.sh \nsed -i 's/CM072627.1.*chromosome 1.*/Chr1/' GCA_036927085.1_ASM3692708v1_genomic.fna\nsed -i 's/CM072628.1.*chromosome 2.*/Chr2/' GCA_036927085.1_ASM3692708v1_genomic.fna\nsed -i 's/CM072629.1.*chromosome 3.*/Chr3/' GCA_036927085.1_ASM3692708v1_genomic.fna\nsed -i 's/CM072630.1.*chromosome 4.*/Chr4/' GCA_036927085.1_ASM3692708v1_genomic.fna\nsed -i 's/CM072631.1.*chromosome 5.*/Chr5/' GCA_036927085.1_ASM3692708v1_genomic.fna\n\nsed -i 's/NC_003070.9.*chromosome 1.*/Chr1/' GCF_000001735.4_TAIR10.1_genomic.fna\nsed -i 's/NC_003071.7.*chromosome 2.*/Chr2/' GCF_000001735.4_TAIR10.1_genomic.fna\nsed -i 's/NC_003074.8.*chromosome 3.*/Chr3/' GCF_000001735.4_TAIR10.1_genomic.fna\nsed -i 's/NC_003075.7.*chromosome 4.*/Chr4/' GCF_000001735.4_TAIR10.1_genomic.fna\nsed -i 's/NC_003076.8.*chromosome 5.*/Chr5/' GCF_000001735.4_TAIR10.1_genomic.fna\n\n(syri) [mpaauw@omics-h0 data]$ cat contig_remover.sh \nsed -i '/&gt;JAWQTX010000006.1/,/^&gt;/d' GCA_036927085.1_ASM3692708v1_genomic.fna\nsed -i '/&gt;JAWQTX010000007.1/,/^&gt;/d' GCA_036927085.1_ASM3692708v1_genomic.fna\n\nsed -i '/&gt;NC_037304.1/,/^&gt;/d' GCF_000001735.4_TAIR10.1_genomic.fna\nsed -i '/&gt;NC_000932.1/,/^&gt;/d' GCF_000001735.4_TAIR10.1_genomic.fna\nLet’s do sanity check: did this work? We do this by using grep, a sophisticated command line search tool, to search for the character &gt;, in all files that are called G*.fna. Note that the * is used as a ‘wildcard’ and we match both genomes with this statement.\n(syri) [mpaauw@omics-h0 data]$ grep \"&gt;\" G*.fna\nGCA_036927085.1_ASM3692708v1_genomic.fna:&gt;Chr1\nGCA_036927085.1_ASM3692708v1_genomic.fna:&gt;Chr2\nGCA_036927085.1_ASM3692708v1_genomic.fna:&gt;Chr3\nGCA_036927085.1_ASM3692708v1_genomic.fna:&gt;Chr4\nGCA_036927085.1_ASM3692708v1_genomic.fna:&gt;Chr5\nGCF_000001735.4_TAIR10.1_genomic.fna:&gt;Chr1\nGCF_000001735.4_TAIR10.1_genomic.fna:&gt;Chr2\nGCF_000001735.4_TAIR10.1_genomic.fna:&gt;Chr3\nGCF_000001735.4_TAIR10.1_genomic.fna:&gt;Chr4\nGCF_000001735.4_TAIR10.1_genomic.fna:&gt;Chr5\nThat looks good. In both genomes, the chromosomes are called Chr1, and so forth."
  },
  {
    "objectID": "posts/Ath_synteny.html#aligning-the-genomes",
    "href": "posts/Ath_synteny.html#aligning-the-genomes",
    "title": "Visualizing Arabidopsis whole-genome alignments",
    "section": "Aligning the genomes",
    "text": "Aligning the genomes\nThe first step is to do a whole-genome alignment between the two genomes. I followed the instructions at plotsr github to do this. We use the software minimap2. This is a quick sequence alignment program and is in installed in base environment on Crunchomics. The alignments are sorted and indexed using samtools. Then syri is used to call structural variants based on the alignment between the two genomes.\nminimap2 -ax asm5 -t 16 --eqx data/GCF_000001735.4_TAIR10.1_genomic.fna data/GCA_036927085.1_ASM3692708v1_genomic.fna | samtools sort -O BAM &gt; Col_Oy.bam\nsamtools index Col_Oy.bam\nsyri -c Col_Oy.bam -r data/GCF_000001735.4_TAIR10.1_genomic.fna -q data/GCA_036927085.1_ASM3692708v1_genomic.fna -F B --prefix Col_Oy\nThis produces several output files:\n(syri) [mpaauw@omics-h0 02_Ath_synteny]$ ls Col_Oysyri.*\nCol_Oysyri.log  Col_Oysyri.out  Col_Oysyri.summary  Col_Oysyri.vcf\nLet’s have a look at the summary.\n(syri) [mpaauw@omics-h0 02_Ath_synteny]$ cat Col_Oysyri.summary \n#Structural annotations\n#Variation_type Count   Length_ref  Length_qry\nSyntenic regions    95  107247075   107294458\nInversions  14  1504073 2295146\nTranslocations  110 566651  566464\nDuplications (reference)    62  267859  -\nDuplications (query)    528 -   898113\nNot aligned (reference) 250 9765159 -\nNot aligned (query) 696 -   20371617\n\n\n#Sequence annotations\n#Variation_type Count   Length_ref  Length_qry\nSNPs    405790  405790  405790\nInsertions  42410   -   904020\nDeletions   41893   867402  -\nCopygains   26  -   485440\nCopylosses  11  15494   -\nHighly diverged 3961    18041314    18376872\nTandem repeats  2   518 599\nOk, so there are quite a few structural variants between Col-0 and Oy-0! The syri.out file contains the details of all the variants individually."
  },
  {
    "objectID": "posts/Ath_synteny.html#plotting-the-structural-variants",
    "href": "posts/Ath_synteny.html#plotting-the-structural-variants",
    "title": "Visualizing Arabidopsis whole-genome alignments",
    "section": "Plotting the structural variants",
    "text": "Plotting the structural variants\nWe can then go ahead and visualize the structural variants using the plotsr software. First we create the genomes.txt file containing info about where the software can find both genomes, how to call them, and specify how they should be plotted.\n(syri) [mpaauw@omics-h0 02_Ath_synteny]$ cat genomes.txt \n#file   name    tags\ndata/GCF_000001735.4_TAIR10.1_genomic.fna   Col lw:1.5\ndata/GCA_036927085.1_ASM3692708v1_genomic.fna   Oy  lw:1.5\n\n# then we run the software: all chromosomes\n(syri) [mpaauw@omics-h0 02_Ath_synteny]$ plotsr --sr Col_Oysyri.out --genomes genomes.txt -o all_chromosomes.png\n\n# or just chromosome 4\n(syri) [mpaauw@omics-h0 02_Ath_synteny]$ plotsr --sr Col_Oysyri.out --genomes genomes.txt --chr Chr4 -o chr4.png\n\nSo, while most of the Chr 4 of the two accessions are syntenic, we can find two inversions, a translocation, and some parts that don’t have a match at all at the chromosome of the other accession."
  },
  {
    "objectID": "posts/Ath_synteny.html#adding-tracks-with-other-data",
    "href": "posts/Ath_synteny.html#adding-tracks-with-other-data",
    "title": "Visualizing Arabidopsis whole-genome alignments",
    "section": "Adding tracks with other data",
    "text": "Adding tracks with other data\nYou can add tracks of data, such as gene annotations, or SNP density, across the genomes. Perhaps you can then discover interesting genomic features that colocalize with the structural variant breakpoints. Here, we have a dataset of short sequences (k-mers) that were mapped to the Col-0 reference genome using the mapping software bowtie. We need to transform the .bam file with the mappings to a .bed file. Then, we need to add “Chr” to the chromosome identifiers in the bed file.\nbedtools bamtobed -i mapping.sorted.bam &gt; mapping.sorted.bed\nawk '{print \"Chr\"$1 \"\\t\" $2 \"\\t\" $3 \"\\t\" $4}' mapping.sorted.bed &gt; mapping.sorted.chr.bed\n(syri) [mpaauw@omics-h0 02_Ath_synteny]$ head mapping.sorted.chr.bed \nChr1    753215  753246  sequence_1703\nChr1    753216  753247  sequence_761\nChr1    753217  753248  sequence_1521\nLet’s continue by generating a tracks.txt file, similar to the genomes.txt file to tell plotsr where to find the track data, how to call the track, and some graphical settings of the track.\n(syri) [mpaauw@omics-h0 02_Ath_synteny]$ cat tracks.txt \n#file   name    tags\nmapping.sorted.chr.bed    sig_kmers   bw:10000;nc:black;ns:8;lc:sienna;lw:1;bc:peachpuff;ba:0.7\n\n(syri) [mpaauw@omics-h0 02_Ath_synteny]$ plotsr --sr Col_Oysyri.out --genomes genomes.txt --tracks tracks.txt --chr Chr5 -W 6 -o Chr5_kmertrack.png\n\nCool! In this case, there is no clear association between our mapped k-mers and structural variation between Col-0 and Oy-0 on this chromosome."
  },
  {
    "objectID": "posts/Ath_synteny.html#further-reading",
    "href": "posts/Ath_synteny.html#further-reading",
    "title": "Visualizing Arabidopsis whole-genome alignments",
    "section": "Further reading",
    "text": "Further reading\n\nsyri, a software package to identify structural rearrangements.\nplotsr, a software package to plot the rearrangements detected by syri.\nLian et al 2024 Nature Genetics.\nclinker, a versatile synteny visualization tool that works on smaller scales (gene clusters)."
  },
  {
    "objectID": "workshop-materials/py-intro/plot.html",
    "href": "workshop-materials/py-intro/plot.html",
    "title": "Workshop image",
    "section": "",
    "text": "Workshop image\n\n\n\nGDP of European countries 1952-2007."
  },
  {
    "objectID": "workshops/2025-introduction-R.html",
    "href": "workshops/2025-introduction-R.html",
    "title": "15 and 17 January 2025: Introduction to R",
    "section": "",
    "text": "The bioDSC organizes an introductory course on data analysis and visualisation in R. R is a programming language for statistical programming and data visualation, and is very popular in the field of biology. Chances are high that those nice figures you see in papers were generated in R! In addition, understanding the basics of R sets you up for more complex data-heavy analysis such as the analysis of RNA-seq data.\nThis workshop assumes no prior knowledge on R or programming!"
  },
  {
    "objectID": "workshops/2025-introduction-R.html#should-i-learn-python-or-r",
    "href": "workshops/2025-introduction-R.html#should-i-learn-python-or-r",
    "title": "15 and 17 January 2025: Introduction to R",
    "section": "Should I learn Python or R?",
    "text": "Should I learn Python or R?\nSee the blog post about Python vs. R in case you’re wondering whether you should start learning: R, or Python. We have more workshops about Python and R coming soon.\n\nSign up\nSign up here. Sign up deadline: 8th of january!"
  },
  {
    "objectID": "workshops/2025-BYOD-1.html",
    "href": "workshops/2025-BYOD-1.html",
    "title": "24 February 2025: Bring Your Own Data",
    "section": "",
    "text": "The bioDSC organizes a “Bring Your Own Data” data visualization workshop. In this workshop, we will offer help and guidance to turn your own dataset into insightful visualizations using ggplot2 in R. You are expected to bring your own table with data to work on, ranging from a small pilot experiment to large-scale experimental assays. We can help improving your existing plotting scripts, or build one from scratch.\nThe aims of this workshop are to help you with:\n\nMaking (publication-quality) plots of your dataset\nWriting reusable scripts to generate more plots later with new datasets\nBecoming more experienced and confident in using R and ggplot2\n\n\n\n\nBoxplots, barplots, and lineplots made in ggplot2, taken from Paauw et al, 2024."
  },
  {
    "objectID": "workshops/2025-BYOD-1.html#bring-your-own-data-data-visualization-workshop",
    "href": "workshops/2025-BYOD-1.html#bring-your-own-data-data-visualization-workshop",
    "title": "24 February 2025: Bring Your Own Data",
    "section": "",
    "text": "The bioDSC organizes a “Bring Your Own Data” data visualization workshop. In this workshop, we will offer help and guidance to turn your own dataset into insightful visualizations using ggplot2 in R. You are expected to bring your own table with data to work on, ranging from a small pilot experiment to large-scale experimental assays. We can help improving your existing plotting scripts, or build one from scratch.\nThe aims of this workshop are to help you with:\n\nMaking (publication-quality) plots of your dataset\nWriting reusable scripts to generate more plots later with new datasets\nBecoming more experienced and confident in using R and ggplot2\n\n\n\n\nBoxplots, barplots, and lineplots made in ggplot2, taken from Paauw et al, 2024."
  },
  {
    "objectID": "workshops/2025-BYOD-1.html#prior-experience",
    "href": "workshops/2025-BYOD-1.html#prior-experience",
    "title": "24 February 2025: Bring Your Own Data",
    "section": "Prior experience",
    "text": "Prior experience\nFor this workshop, we assume that you have some experience with data manipulation and visualisation in R, using the tidyverse packages dplyr, tidyr and ggplot2. For example, you have followed our recent workshop Introduction to R where we covered the materials of R for Social Scientists. Alternatively, you have similar experience from other courses or your own explorations."
  },
  {
    "objectID": "workshops/2025-BYOD-1.html#workshop-logistics",
    "href": "workshops/2025-BYOD-1.html#workshop-logistics",
    "title": "24 February 2025: Bring Your Own Data",
    "section": "Workshop logistics",
    "text": "Workshop logistics\nIn this workshop, you will work by yourself on your own dataset. Martijn Wehrens, Misha Paauw, and Frans van der Kloet from the bioDSC will be available to discuss your approach and help you with all the problems you encounter along the way. There is room for 4-12 participants. You have to bring your own laptop, with and R and RStudio installed, including the tidyverse package."
  },
  {
    "objectID": "workshops/2025-BYOD-1.html#workshop-schedule",
    "href": "workshops/2025-BYOD-1.html#workshop-schedule",
    "title": "24 February 2025: Bring Your Own Data",
    "section": "Workshop schedule",
    "text": "Workshop schedule\n\n\n\n\n\n\n\n\n\nDate\nTime\nLocation\nTopic\n\n\n\n\nMonday 24 february\n13:00 - 16:00\nScience Park B0.206\nVisualisation of datasets"
  },
  {
    "objectID": "workshops/2025-BYOD-1.html#sign-up",
    "href": "workshops/2025-BYOD-1.html#sign-up",
    "title": "24 February 2025: Bring Your Own Data",
    "section": "Sign up",
    "text": "Sign up\nSign up by sending an email to info@biodsc.nl.\nIn your email, please include the following:\n\nYour research group\nYour dataset in comma separated, tab separated, or excel table format (.csv, .tsv, .xlsx).\nA brief explanation of your dataset and the plots you want to make\nIdeally, a quick sketch of the plot you want to make\n\nSign up deadline: 19th of february!"
  },
  {
    "objectID": "workshops/2025-introduction-python.html",
    "href": "workshops/2025-introduction-python.html",
    "title": "March 12 and 14 (2025): Introduction to Python",
    "section": "",
    "text": "This workshop is full.\n\n\n\n12 people have registered, we do not have place for more participants. Unfortunately, you cannot register any more.\nPlease send us an email in case you were interested in signing up, such that we know to organize more workshops soon.\n\n\n\nAn introduction to Python\nThe bioDSC organizes an introductory workshop that will cover basic functionalities of Python.\nPython is a computer script language that has become a workhorse of data analysis throughout many fields and disciplines. It can process and analyze big data sets, perform image analysis, and create great visualizations.\nSee below for small overview of what types of tasks can be done using Python.\n\n\nWorkshop goals\nAfter this workshop, you’ll be familiar with Python basics. We’ll discuss and let you practice on:\n\n\nUsing Python (Jupyter notebooks, VS Studio code, Spyder)\n\nThroughout the workshop, we’ll use an online version of Jupyter notebook to avoid installation issues)\n\nVariables, types, basic commands, functions, libraries.\nWorking with tabular data (Pandas).\nPlotting (matplotlib).\nUsing loops and conditionals.\nWriting functions.\nGood practices in programming and software engineering.\n\n\nThis workshop will largely (&gt;95%) follow the Carpentries training material “Plotting and programming in Python”. All training material can be found at:\n\nhttps://swcarpentry.github.io/python-novice-gapminder/\n\nSee this workshop page for a summary of desired learning results. The materials we’ll use do not use examples specific to biology, but instead use the “Gapminder” dataset (see [1] and [2]). We think this offers thorough insights into how Python works. Follow-up courses, e.g. into image analysis, will be delve into more biological datasets.\nIf you have any questions regarding whether this course is relevant for you, please send us an email (info@biodsc.nl) or walk by our desks.\n\n\nRequirements\nThis workshop assumes no prior knowledge on Python or programming!\n\n\nWorkshop logistics\nThe course will be given by Martijn Wehrens and Misha Paauw from the bioDSC. There is room for 4-12 participants. You have to bring your own laptop, we’ll use an online version of Python, so there are no software installation requirements.\nAs mentioned, the contents of this workshops are almost completely based on: https://swcarpentry.github.io/python-novice-gapminder/\n\n\nWorkshop schedule\n\n\n\n\n\n\n\n\n\nDate\nTime\nLocation\nTopic\n\n\n\n\n12 March\n12:30 - 17:30\nSP A1.06\nIntroduction to Python, episodes 1-9\n\n\n14 March\n12:30 - 17:30\nSP B0.209\nIntroduction to Python, episodes 11-18\n\n\n\n\n\nSign up\n\n\n\n\n\n\n\nThis workshop is full.\n\n\n\n12 people have registered, we do not have place for more participants. Unfortunately, you cannot register any more.\nPlease send us an email in case you were interested in signing up, such that we know to organize more workshops soon.\n\n\n\n\n\nTypical use cases for Python\nPython is a scripting language, meaning that your write a file with commands for the computer to execute. This allows you to perform complicated tasks, such as:\n\n\nPlotting and analyzing large data sets\n\nWith the pandas, matplotlib, and seaborn library, large datasets can be imported, manipulated, and visualized\n\nImage analysis\n\nPython has become a great open-source tool for image analysis\nMultiple libraries are now available that can do pretty much any “classical” image operations to analyze images. You can:\n\nSegment your image (identify cells, or other parts of your image that are of interest)\nExtract summary parameters relevant for your analysis.\nRelated libraries: scikit-image, SciPy, OpenCV, ..\n\nMultiple tools exist to allow smooth user-interaction, such as Napari\n\nMachine learning, neural networks, LLM, AI\n\nPython has become the go-to tool for working with machine learning related tech\n\nLibraries: E.g. Keras and PyTorch\n\n\nHigh-throughput data analysis and automation\n\nPython is often used to process large amounts of data for further processing (see bio-informatics below)\n\nBioinformatics\n\nCan be used to handle, manipulate, process, quantify raw sequence data or similar.\nPerform single cell analysis, e.g. using the SCANPY lirbary.\nNot the tool for RNA-seq statistics and gene expression analysis, for which R is superior.\n\nMuch more ..\n\n\nSee also the post I wrote earlier to decide whether you should Python or R."
  },
  {
    "objectID": "workshops/2025-introduction-python-2.html",
    "href": "workshops/2025-introduction-python-2.html",
    "title": "April 2 and 4 (2025): Introduction to Python",
    "section": "",
    "text": "An introduction to Python\nThe bioDSC organizes an introductory workshop that will cover basic functionalities of Python.\nPython is a computer script language that has become a workhorse of data analysis throughout many fields and disciplines. It can process and analyze big data sets, perform image analysis, and create great visualizations.\nSee below for small overview of what types of tasks can be done using Python.\n\n2nd session\nThis workshop will be exactly the same as the previous one. We are simply organizing another session since the previous workshop was booked completely full.\n\n\n\nWorkshop goals\nAfter this workshop, you’ll be familiar with Python basics. We’ll discuss and let you practice on:\n\n\nUsing Python (Jupyter notebooks, VS Studio code, Spyder)\n\nThroughout the workshop, we’ll use an online version of Jupyter notebook to avoid installation issues)\n\nVariables, types, basic commands, functions, libraries.\nWorking with tabular data (Pandas).\nPlotting (matplotlib).\nUsing loops and conditionals.\nWriting functions.\nGood practices in programming and software engineering.\n\n\nThis workshop will largely (&gt;95%) follow the Carpentries training material “Plotting and programming in Python”. All training material can be found at:\n\nhttps://swcarpentry.github.io/python-novice-gapminder/\n\nSee this workshop page for a summary of desired learning results. The materials we’ll use do not use examples specific to biology, but instead use the “Gapminder” dataset (see [1] and [2]). We think this offers thorough insights into how Python works. Follow-up courses, e.g. into image analysis, will be delve into more biological datasets.\nIf you have any questions regarding whether this course is relevant for you, please send us an email (info@biodsc.nl) or walk by our desks.\n\n\nRequirements\nThis workshop assumes no prior knowledge on Python or programming!\n\n\nWorkshop logistics\nThe course will be given by Martijn Wehrens and Misha Paauw from the bioDSC. There is room for 4-12 participants. You have to bring your own laptop, we’ll use an online version of Python, so there are no software installation requirements.\nAs mentioned, the contents of this workshops are almost completely based on: https://swcarpentry.github.io/python-novice-gapminder/\n\n\nWorkshop schedule\n\n\n\n\n\n\n\n\n\nDate\nTime\nLocation\nTopic\n\n\n\n\nApril 2\n13:00 - 17:30\nSP L1.13\nIntroduction to Python, episodes 1-9\n\n\nApril 4\n12:30 - 17:30\nSP L2.06\nIntroduction to Python, episodes 11-18\n\n\n\n\n\nSign up\nSign up using this link. \n\n\n\n\nTypical use cases for Python\nPython is a scripting language, meaning that your write a file with commands for the computer to execute. This allows you to perform complicated tasks, such as:\n\n\nPlotting and analyzing large data sets\n\nWith the pandas, matplotlib, and seaborn library, large datasets can be imported, manipulated, and visualized\n\nImage analysis\n\nPython has become a great open-source tool for image analysis\nMultiple libraries are now available that can do pretty much any “classical” image operations to analyze images. You can:\n\nSegment your image (identify cells, or other parts of your image that are of interest)\nExtract summary parameters relevant for your analysis.\nRelated libraries: scikit-image, SciPy, OpenCV, ..\n\nMultiple tools exist to allow smooth user-interaction, such as Napari\n\nMachine learning, neural networks, LLM, AI\n\nPython has become the go-to tool for working with machine learning related tech\n\nLibraries: E.g. Keras and PyTorch\n\n\nHigh-throughput data analysis and automation\n\nPython is often used to process large amounts of data for further processing (see bio-informatics below)\n\nBioinformatics\n\nCan be used to handle, manipulate, process, quantify raw sequence data or similar.\nPerform single cell analysis, e.g. using the SCANPY lirbary.\nNot the tool for RNA-seq statistics and gene expression analysis, for which R is superior.\n\nMuch more ..\n\n\nSee also the post I wrote earlier to decide whether you should Python or R."
  },
  {
    "objectID": "workshops/2025-working-on.html",
    "href": "workshops/2025-working-on.html",
    "title": "List of past and upcoming workshops",
    "section": "",
    "text": "Below a list of planned workshops:\n\nAn introduction to R (Jan 2025)\n\nBasics of R\nImporting, manipulating and analyzing data (mostly using dataframes).\nPlotting using ggplot.\n\nBring your own data (February 25th, 2025)\n\nBring your own dataset and make publication-quality figures.\n\nAn introduction to Python (March 12 & 14, 2025).\n\nVariables, types, basic commands, functions, libraries.\nWorking with tabular data (Pandas).\nPlotting (matplotlib).\nUsing loops and conditionals, writing functions.\nGood practices in programming and software engineering.\n\nImage analysis with Python (planning: April/May 2025).\n\nBasics of working with images\nImage manipulation, cellular segmentation, and other often-used concepts.\n(..)\n\nAnalysis of RNA-sequencing data (planning: April/May 2025)\n\nRead quality control\nMapping reads to a reference genome\nDifferentially expressed gene analysis using DEseq2 in R.\n\n\nWe aim to give workshops based on demand. So if there’s enough people interested, workshops will be recurring."
  },
  {
    "objectID": "workshops/2025-working-on.html#should-i-learn-python-or-r",
    "href": "workshops/2025-working-on.html#should-i-learn-python-or-r",
    "title": "List of past and upcoming workshops",
    "section": "Should I learn Python or R?",
    "text": "Should I learn Python or R?\nSee the blog post about Python vs. R in case you’re wondering whether you should start learning: R, or Python."
  },
  {
    "objectID": "workshop-materials/index.html",
    "href": "workshop-materials/index.html",
    "title": "Overview",
    "section": "",
    "text": "Overview\n\nFor the example plot, see here: link.\nFor additional exercises, see here: additional exercises."
  },
  {
    "objectID": "workshop-materials/py-intro/additional_exercises.html",
    "href": "workshop-materials/py-intro/additional_exercises.html",
    "title": "Additional exercises for fast participants",
    "section": "",
    "text": "What’s happening here:\n\n# use Google or chatGPT if you don't know the answers\n# if you're at the end, try to play around more\n\ngreetings_strings = ['hello', 'bye', 'later']\nprint(greetings_strings[0])\nprint(greetings_strings[1][2])\n    # (list of lists)\n\nprint([greetings_strings[idx] for idx in [0, 2]])\nprint([greetings_strings[0][idx] for idx in [0, 2, 4]])\nprint([greetings_strings[0][idx] for idx in range(0,4,2)])\n    # using a loop (will be covered later) / list comprehension\n\nsquare_values = [number**2 for number in range(10)]\nsquare_values_string = [str(number**2) for number in range(10)]\nprint(square_values)\nprint(square_values_string)\n    # types will be the topic of the next lesson\n\nspecies_name = \"Acacia buxifolia\"\nprint(\"\".join([species_name[i] for i in range(10, 2, -1)]))\n    # convenient command when working with strings\n\nprint(species_name.replace('Aca', 'Bole'))\n    # another convenient command\n\n# Exercise:\nlist_of_species = ['','','','']\nlist_of_species = ['Homo sapiens', 'Escherichia Coli', 'Pan troglodytes', 'Canis lupus', 'Felis catus']\n# Create a new lists, where you remove all letters 'e'"
  },
  {
    "objectID": "workshop-materials/py-intro/additional_exercises.html#lesson-2",
    "href": "workshop-materials/py-intro/additional_exercises.html#lesson-2",
    "title": "Additional exercises for fast participants",
    "section": "",
    "text": "What’s happening here:\n\n# use Google or chatGPT if you don't know the answers\n# if you're at the end, try to play around more\n\ngreetings_strings = ['hello', 'bye', 'later']\nprint(greetings_strings[0])\nprint(greetings_strings[1][2])\n    # (list of lists)\n\nprint([greetings_strings[idx] for idx in [0, 2]])\nprint([greetings_strings[0][idx] for idx in [0, 2, 4]])\nprint([greetings_strings[0][idx] for idx in range(0,4,2)])\n    # using a loop (will be covered later) / list comprehension\n\nsquare_values = [number**2 for number in range(10)]\nsquare_values_string = [str(number**2) for number in range(10)]\nprint(square_values)\nprint(square_values_string)\n    # types will be the topic of the next lesson\n\nspecies_name = \"Acacia buxifolia\"\nprint(\"\".join([species_name[i] for i in range(10, 2, -1)]))\n    # convenient command when working with strings\n\nprint(species_name.replace('Aca', 'Bole'))\n    # another convenient command\n\n# Exercise:\nlist_of_species = ['','','','']\nlist_of_species = ['Homo sapiens', 'Escherichia Coli', 'Pan troglodytes', 'Canis lupus', 'Felis catus']\n# Create a new lists, where you remove all letters 'e'"
  },
  {
    "objectID": "workshop-materials/py-intro/additional_exercises.html#exercises-for-fast-participants-1",
    "href": "workshop-materials/py-intro/additional_exercises.html#exercises-for-fast-participants-1",
    "title": "Additional exercises for fast participants",
    "section": "Exercises for fast participants",
    "text": "Exercises for fast participants\n\nCreate a plain text file on your computer, and give it the extension .csv.\nFind out what the comma-separated format looks like.\nUse your imagination to complete the following table and put it in the .csv file.\n\n\n\n\nreplicate\ncond1\ncond2\n\n\n\n\n\n10\n\n\n\n\n11\n\n\n\n\n10\n\n\n\n\n12\n\n\n\n\n13\n\n\n\n\n13\n\n\n\n\n\nNow try to read in that table in your python notebook.\nGet the following code to run on your dataframe (referred to as df below):\n\nfrom scipy.stats import ttest_ind\nt_stat, p_value = ttest_ind(df['cond1'], df['cond2'])\nprint(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n\nWhat does that code do?\nDo a “Diederik Stapel” and tweak the csv such that you get a significant p-val."
  },
  {
    "objectID": "workshop-materials/py-intro/additional_exercises.html#additional-exercises-for-fast-participants-1",
    "href": "workshop-materials/py-intro/additional_exercises.html#additional-exercises-for-fast-participants-1",
    "title": "Additional exercises for fast participants",
    "section": "Additional exercises for fast participants",
    "text": "Additional exercises for fast participants\n\nGDPs\n\nBetween ’87 and ’92 the GDP of most countries took a hit. Are there any countries which had a positive increase between those two years? Which ones?\nCalculate the average GDP between all European countries per year.\n\nNormalize the dataframe by this trend.\n\n\n\n\nGene expression\n\nConvert the data below to a csv file, import it to a pandas df, and determine the following:\n\nThe average CRP gene expression per condion.\nThe corresponding standard deviations.\nThe log2-fold change between WT, condition A, and condition B.\nDo the same for ACTA1.\nNormalize all gene expression levels to their average respective wild type levels.\n\n\ngene    expression  condition\nCRP 873 WT\nCRP 324 WT\nCRP 214 WT\nCRP 151 WT\nCRP 1220    A\nCRP 450 A\nCRP 300 A\nCRP 210 A\nCRP 800 B\nCRP 200 B\nCRP 200 B\nCRP 130 B\nACTA1   7457    WT\nACTA1   2342    WT\nACTA1   8000    WT\nACTA1   9000    WT\nACTA1   6500    A\nACTA1   2200    A\nACTA1   7500    A\nACTA1   8000    A\nACTA1   1000    B\nACTA1   1123    B\nACTA1   3211    B\nACTA1   1231    B"
  },
  {
    "objectID": "workshop-materials/py-intro/additional_exercises.html#exercises-for-fast-participants-2",
    "href": "workshop-materials/py-intro/additional_exercises.html#exercises-for-fast-participants-2",
    "title": "Additional exercises for fast participants",
    "section": "Exercises for fast participants",
    "text": "Exercises for fast participants\n\nNormalized dataframe\n\nIn the previous exercise, we normalized the GDP data against the average trend. Plot the data from this normalized dataframe.\n\nIs this helpful in any way?\n\n\n\n\nCrude oil\nCrude oil prices can be found at: https://www.eia.gov/dnav/pet/hist/LeafHandler.ashx?n=PET&s=F000000__3&f=A\nThis gives the data below:\nDecade  Year-0  Year-1  Year-2  Year-3  Year-4  Year-5  Year-6  Year-7  Year-8  Year-9\n  1850's                                        16.00\n  1860's    9.59    0.49    1.05    3.15    8.06    6.59    3.74    2.41    3.62    5.64\n  1870's    3.86    4.34    3.64    1.83    1.17    1.35    2.52    2.38    1.17    0.86\n  1880's    0.94    0.92    0.78    1.10    0.85    0.88    0.71    0.67    0.65    0.77\n  1890's    0.77    0.56    0.51    0.60    0.72    1.09    0.96    0.68    0.80    1.13\n  1900's    1.19    0.96    0.80    0.94    0.86    0.62    0.73    0.72    0.72    0.70\n  1910's    0.61    0.61    0.74    0.95    0.81    0.64    1.10    1.56    1.98    2.01\n  1920's    3.07    1.73    1.61    1.34    1.43    1.68    1.88    1.30    1.17    1.27\n  1930's    1.19    0.65    0.87    0.67    1.00    0.97    1.09    1.18    1.13    1.02\n  1940's    1.02    1.14    1.19    1.20    1.21    1.22    1.41    1.93    2.60    2.54\n  1950's    2.51    2.53    2.53    2.68    2.78    2.77    2.79    3.09    3.01    2.90\n  1960's    2.88    2.89    2.90    2.89    2.88    2.86    2.88    2.92    2.94    3.09\n  1970's    3.18    3.39    3.39    3.89    6.87    7.67    8.19    8.57    9.00    12.64\n  1980's    21.59   31.77   28.52   26.19   25.88   24.09   12.51   15.40   12.58   15.86\n  1990's    20.03   16.54   15.99   14.25   13.19   14.62   18.46   17.23   10.87   15.56\n  2000's    26.72   21.84   22.51   27.56   36.77   50.28   59.69   66.52   94.04   56.35\n  2010's    74.71   95.73   94.52   95.99   87.39   44.39   38.29   48.05   61.40   55.59\n  2020's    36.86   65.84   93.97   76.10                       \nSave that data to a .tsv file, and upload it.\nNow try to understand the code below:\nimport pandas as pd\n\n# Load the data\ndf_crudeoil = \\\n    pd.read_csv('/Users/m.wehrens/Data_UVA/2024_teaching/2025-03-gapminder/crude_oil/crude_oil_prices.tsv', sep='\\t')\n\n# reshape the data, such that it becomes a long list\ndf_crudeoil_melted = df_crudeoil.melt(id_vars='Decade', var_name='lastdigit')\n\n# now reformat the year information\n# search and replace first\ndf_crudeoil_melted.loc[:,'Decade'] = df_crudeoil_melted.loc[:,'Decade'].str.replace(\"0's\",'')\ndf_crudeoil_melted.loc[:,'lastdigit'] = df_crudeoil_melted.loc[:,'lastdigit'].str.replace('Year-','')\n# now combine information to create a new column \"Year\"\ndf_crudeoil_melted.loc[:,'Year'] = df_crudeoil_melted.loc[:,'Decade'] + df_crudeoil_melted.loc[:,'lastdigit']\n# Inspect the result\nprint(df_crudeoil_melted.head())\nUsing your plotting skills, compare this data against the trends in the Asian GDPs showed earlier.\n\n\nEven more correlations\nIn the “More Correlations” exercise, try to add the following lines to the plotting code:\nplt.text(df_all.loc['United States','gdpPercap_2007'], df_all.loc['United States','lifeExp_2007'], 'United States')\nplt.text(df_all.loc['Netherlands','gdpPercap_2007'], df_all.loc['Netherlands','lifeExp_2007'], 'Netherlands')\n\nWhat’s happening here?\nPerhaps also add your favorite country too?\nHow would you add labels for the top 10 GDP countries?\n\nNote: in the next lessons, we’ll learn how to automate your code. This will be very useful for this particular challenge.\n\n\n\n\nSeaborn\n\nMatplotlib.pyplot can in principle cater all your needs. A nice addition however is Seaborn.\n\nThis is another plotting tool is seaborn, which works well with matplotlib and pandas dataframes\nGo to https://seaborn.pydata.org/examples/index.html\nTry to use seaborn to make some nice plots of the data we’ve been looking at using those examples"
  },
  {
    "objectID": "posts/introduction.html",
    "href": "posts/introduction.html",
    "title": "The bioDSC blog: first post",
    "section": "",
    "text": "We want to use this blog to share, every now and then, what’s on our minds. For example, let’s say we read a few interesting papers on a new bioinformatics technique. Sometimes we install the tools, to see if we can get it to work on our own data, or on a small test dataset. It might not develop into a full tutorial or protocol, but instead of keeping it to ourselves, we will share it here on this blog. Who knows, maybe it’s useful for someone in the future!\nTopics we aim to cover:\n\nBioinformatics, from RNA-seq to comparative genomics and anything beyond that\nData visualization, focussing on the ggplot universe in R\nCrunchomics, tips and tricks to use the high-performance compute cluster of the University of Amsterdam\nData management and archiving\n\nDo not hesitate to send us an email if you have ideas for new topics, or if you want to contribute to the blog by co-authoring a post!"
  },
  {
    "objectID": "posts/introduction.html#why-a-blog",
    "href": "posts/introduction.html#why-a-blog",
    "title": "The bioDSC blog: first post",
    "section": "",
    "text": "We want to use this blog to share, every now and then, what’s on our minds. For example, let’s say we read a few interesting papers on a new bioinformatics technique. Sometimes we install the tools, to see if we can get it to work on our own data, or on a small test dataset. It might not develop into a full tutorial or protocol, but instead of keeping it to ourselves, we will share it here on this blog. Who knows, maybe it’s useful for someone in the future!\nTopics we aim to cover:\n\nBioinformatics, from RNA-seq to comparative genomics and anything beyond that\nData visualization, focussing on the ggplot universe in R\nCrunchomics, tips and tricks to use the high-performance compute cluster of the University of Amsterdam\nData management and archiving\n\nDo not hesitate to send us an email if you have ideas for new topics, or if you want to contribute to the blog by co-authoring a post!"
  },
  {
    "objectID": "workshops.html",
    "href": "workshops.html",
    "title": "Workshops & events",
    "section": "",
    "text": "Get introduced to the Python from simple basics to functions, dataframes and plotting.\n\n\n\n\n\nApr 2, 2025\n\n\nMartijn Wehrens\n\n\n\n\n\n\n\n\n\n\n\nGet introduced to the Python from simple basics to functions, dataframes and plotting.\n\n\n\n\n\nMar 12, 2025\n\n\nMartijn Wehrens\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "workshops.html#upcoming-workshops",
    "href": "workshops.html#upcoming-workshops",
    "title": "Workshops & events",
    "section": "",
    "text": "Get introduced to the Python from simple basics to functions, dataframes and plotting.\n\n\n\n\n\nApr 2, 2025\n\n\nMartijn Wehrens\n\n\n\n\n\n\n\n\n\n\n\nGet introduced to the Python from simple basics to functions, dataframes and plotting.\n\n\n\n\n\nMar 12, 2025\n\n\nMartijn Wehrens\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "workshops.html#stay-tuned",
    "href": "workshops.html#stay-tuned",
    "title": "Workshops & events",
    "section": "Stay tuned",
    "text": "Stay tuned\n\n\n\n\n\nList of past and upcoming workshops\n\n\n\n\n\nWorkshops we are currently developing that are coming soon.\n\n\n\n\n\nMar 1, 2025\n\n\nMartijn Wehrens\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "workshops.html#past-workshops",
    "href": "workshops.html#past-workshops",
    "title": "Workshops & events",
    "section": "Past workshops",
    "text": "Past workshops\n\n\n\n\n\n24 February 2025: Bring Your Own Data\n\n\n\n\n\nBring your own dataset and make publication-quality figures.\n\n\n\n\n\nFeb 24, 2025\n\n\nMisha Paauw\n\n\n\n\n\n\n\n15 and 17 January 2025: Introduction to R\n\n\n\n\n\nLearn the basics of data analysis and visualisation in R in this workshop.\n\n\n\n\n\nJan 15, 2025\n\n\nMisha Paauw\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "people.html",
    "href": "people.html",
    "title": "bioDSC core team",
    "section": "",
    "text": "Our core team consists of three members; Frans van der Kloet, Martijn Wehrens and Misha Paauw."
  },
  {
    "objectID": "people.html#frans-van-der-kloet",
    "href": "people.html#frans-van-der-kloet",
    "title": "bioDSC core team",
    "section": "Frans van der Kloet",
    "text": "Frans van der Kloet\n\n\nInfo\nI obtained my BSc at the Noordelijke Hogeschool (NHL) in Leeuwarden majoring in analytical chemistry and got my MSc in Computational Chemistry at the Radboud University in Nijmegen. After several jobs in commercial companies I continued my academic career in 2009 and obtained my PhD at the Leiden University on quantitative aspects in/of high resolution mass spectrometry data in metabolomics in 2014. In that same year I started as a post-doc at the BDA group working on aspects of multi-block/view solutions like JIVE, DISCO and OnPLS and incorporating these types of methods in the prediction/classification of in-vivo transcriptome data. After another PD position at the Amsterdam Medical Center I started as a data scientist in the BDA group in 2019.\nCurrent activities concern administration and implementation of a local Galaxy Server. Development of a database to store meta-data on samples/measurements (Metatree). Deployment of DL tools in the deconvolution of HRMS data and learning from DL models in general.\nMy main interest is in (pre)processing of large data-sets (with a preference for high resolution mass spectrometry data) and the development and implementation of data-analysis and pre-processing tools that is often further complicated because of these large data sizes.\n\n\nKeywords:\nPython, C++, C, Matlab, (R), Java, Galaxy(project), Metabolomics, MS, (multivariate) data analysis, (learning from) DL models.\n\n\nContact:\nGroup: Biosystems Data Analysis\nOffice: SP C2-205\nEmail: f.m.vanderkloet@uva.nl"
  },
  {
    "objectID": "people.html#martijn-wehrens",
    "href": "people.html#martijn-wehrens",
    "title": "bioDSC core team",
    "section": "Martijn Wehrens",
    "text": "Martijn Wehrens\n\nAfter studying biology and chemistry in Nijmegen (BSc, RU), I obtained a MSc degree in theoretical chemistry at the University of Amsterdam, during which I focussed on simulations of biomolecular networks. Remaining in Amsterdam, I then obtained my PhD at AMOLF, where I worked on tracking single bacteria using time lapse microscopy to understand gene regulation at the single cell. After finishing my PhD, I moved to the Hubrecht Institute in Utrecht where I used RNA-sequencing to investigate the pathogenesis of heart disease as a postdoc.\nAt the bioDSC, I have fun writing scripts and lending my various computational and quantitative expertise to further understand all the amazing biological processes that occur in cells.\n\nKeywords:\nImage analysis, quantitative biology, RNA-seq and sequencing pipelines, data analysis in Python and R.\n\n\nContact:\nGroup: Molecular Cytology\nOffice: SP C2.267a\nEmail: m.wehrens@uva.nl"
  },
  {
    "objectID": "people.html#misha-paauw",
    "href": "people.html#misha-paauw",
    "title": "bioDSC core team",
    "section": "Misha Paauw",
    "text": "Misha Paauw\n\n\nInfo\nAfter a broad training in biology during my BSc and MSc, ranging from ecology to bioinformatics to molecular plant biology, I started my PhD in the Molecular Plant Pathology group of the University of Amsterdam in 2019. In my PhD research, I worked on the molecular interactions between plants and a pathogenic bacterium, called Xanthomonas campestris pv. campestris (Xcc). By studying the ‘pangenome’ of Xcc, I reconstructed the evolutionary history of Xcc and pinpointed the genes required for the specific infection strategy of Xcc.\nIn my current role as data scientist I support molecular biologists in their data-heavy projects by providing individual consultancy and organizing workshops via the bioDSC.\n\n\nKeywords:\nPython, R, bash, data visualisation, comparative genomics, microbial genomics, molecular (plant) biology.\n\n\nContact:\nGroup: Plant Physiology, Green Life Sciences\nOffice: SP C2-207\nEmail: m.m.paauw@uva.nl"
  },
  {
    "objectID": "people.html#other-contributors",
    "href": "people.html#other-contributors",
    "title": "bioDSC core team",
    "section": "Other contributors",
    "text": "Other contributors\n\nAnna Heintz-Buschart (BDA, SILS)\nTijs Bliek (PDEG, SILS)\nNina Dombrowski (IBED)\nWim de Leeuw (MAD, SILS)"
  },
  {
    "objectID": "further-reading.html",
    "href": "further-reading.html",
    "title": "*bio*DSC",
    "section": "",
    "text": "Here, we will provide links to other useful pages on the intersection between biology and data science. Send us an email if you maintain a page or blog with useful biology-related programming tips and tricks, and wish to be included in these lists.\n\n\n\nCrunchomics documentation\nThe IBED bioinformatics support page\n\n\n\n\n\nDataViz protocols by Joachim Goedhart\nFundamentals of Data Visualization by Claus Wilke\nAn introduction to good color schemes\n\n\n\n\n\nMeta-Omics tutorials by Anna Heintz-Buschart"
  },
  {
    "objectID": "further-reading.html#further-reading",
    "href": "further-reading.html#further-reading",
    "title": "*bio*DSC",
    "section": "",
    "text": "Here, we will provide links to other useful pages on the intersection between biology and data science. Send us an email if you maintain a page or blog with useful biology-related programming tips and tricks, and wish to be included in these lists.\n\n\n\nCrunchomics documentation\nThe IBED bioinformatics support page\n\n\n\n\n\nDataViz protocols by Joachim Goedhart\nFundamentals of Data Visualization by Claus Wilke\nAn introduction to good color schemes\n\n\n\n\n\nMeta-Omics tutorials by Anna Heintz-Buschart"
  }
]